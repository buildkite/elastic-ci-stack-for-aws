#!/bin/bash

# This script leverages the AWS CLI to collect Elastic Stack logs for your
# Buildkite Elastic CI Stack instances.
#
# It assumes you have the AWS CLI tool configured, with appropriate credentials
# so it is recommended to use something like aws-vault: https://github.com/99designs/aws-vault.
#
# You will need to know the Instance ID and Stack name of the resources
# you want to collect logs for.
# 
# Once you have collected the logs, please send them to support@buildkite.com
# with a description of the issue you are seeing, and we'll be happy to assist!

set -euo pipefail

usage() {
cat << EOF
Usage: $0 -s <stack-name> -i <instance-id>
Collect Buildkite Elastic CI stack logs from AWS CloudWatch
-s      Stack name, can be found at https://console.aws.amazon.com/cloudformation/home
-i      Instance ID, the AWS instance ID for the instance you want to collect logs for
-o      Output format for logs (optional flag), supported values are text (default value), json, table
EOF
}

while getopts 'hs:i:o:' opt; do
    case ${opt} in
        s ) 
            stackName=$OPTARG
            ;;
        i )
            instanceId=$OPTARG
            ;;
        o )
            outputFormat=$OPTARG
            ;;
        h )
            usage
            exit 0
            ;;
        \? )
            echo "Invalid Option: -$OPTARG" 1>&2
            exit 1
            ;;
        : )
            echo "Invalid option: $OPTARG requires an arguemnt" 1>&2
            ;;
    esac
done
shift $((OPTIND -1))

now=$(date +"%F")
outputFormat="${outputFormat:=text}"

# Create a temporary directory to store our logs
dir=$(mktemp -d buildkite-logs-"$now"-XXXX)

echo "Collecting logs for instance $instanceId"

# Collect the logs for the instance
for name in buildkite-agent system lifecycled docker-daemon; do
    aws logs get-log-events \
        --log-group-name "/buildkite/$name" \
        --log-stream-name "$instanceId" \
        --output "$outputFormat" \
        >> "$dir/$name-$instanceId.log"
done

# CloudWatch stores the creationTime as milliseconds since epoch UTC. 
# Since macOS doesn't support calculating the time since epoch in milliseconds, we don't have perfect accuracy on this, but it should be as close to 24 hours as possible
# We'll check to see if we're running on a macOS-based OS and adjust appropriately, otherwise use the standard date command

# Currently only collects the last 24h of logs, but it might be good to be able to specify a different value for this.

logAge=$(date --date="1day" "+%s000")

# check if we're running on a macOS based system
if [[ $OSTYPE == 'darwin'* ]]; then
    logAge=$(date -v-1d "+%s000")
fi



# Collect some information about the Lambda function and associated log groups
lambdaFunction=$(aws cloudformation describe-stack-resources --stack-name "$stackName" --logical-resource-id Autoscaling --query "StackResources[*].PhysicalResourceId" --output text | sed -nr 's/.*stack\/(.*)\/.*/\1/p')
lambdaLogGroup=$(aws cloudformation describe-stack-resources --stack-name "$lambdaFunction" --logical-resource-id LogGroup --query "StackResources[*].PhysicalResourceId" --output text)
logStreams=$(aws logs describe-log-streams --log-group-name "$lambdaLogGroup" --order-by LastEventTime --query "logStreams[?creationTime > \`$logAge\`] | [*].logStreamName" --output text | tr -s '[:space:]' '\n')

# Iterate through all of the log streams we collected from the lambda log group
echo "Collecting Lambda logs for $lambdaFunction"
for i in $logStreams
do
    fileName=$(echo "$i" | sed -r 's/\//-/g')
    aws logs get-log-events --log-group-name "$lambdaLogGroup" \
        --log-stream-name "$i" \
        --output "$outputFormat" \
        >> "${dir}/lambda-${fileName}.log"
done

# Collect ASG activity for the scaling group
autoScalingGroup=$(aws cloudformation describe-stack-resources --stack-name "$stackName" --logical-resource-id AgentAutoScaleGroup --query "StackResources[*].PhysicalResourceId" --output text)
echo "Collecting ASG activity for $autoScalingGroup"
aws autoscaling describe-scaling-activities --auto-scaling-group-name "$autoScalingGroup" >> "${dir}/asg-activities-${stackName}.log"

# Make an archive with the logs
tar -czvf buildkite-logs-"$now".tar.gz "$dir"/*.log

# Clean up the unneeded files
rm -r "$dir"

echo "Finished collecting logs, you can find them here: $PWD/buildkite-logs-${now}.tar.gz"

exit 0